{"./":{"url":"./","title":"Introduction","keywords":"","body":"Ops Ops 是一个运维工具项目。它的目标是提供一个简单的运维工具，让运维人员可以快速地完成运维工作。 生产实践 日构建 2k+ 的 CICD 集群 海外集群 40+ 个集群 AI 算力集群 7+ 个集群 支持 ARM、X86 架构 设计 对象定义 Host，主机。可以是云主机、裸金属机器，通过 SSH 能够访问到的机器。 Cluster，Kubernetes 集群。通过 kubectl 能够访问的 Kubernetes 集群。 Task，组合多个 File 和 Shell 的任务。 Pipeline，组合多个 Task 的任务。 核心操作 File，文件的上传和下发。 Shell，执行脚本。 组件 ops-cli，是可以单独使用的命令行工具，辅助运维人员在命令行终端完成一些自动化的运维工作 ops-server 一个 HTTP 服务，用于提供 HTTP API，提供有一个 Dashboard 的界面 ops-controller，以 Operator 的形式管理主机、集群、任务、流水线等资源 多集群支持 在实践中，建议: 将当前集群的主机创建为 Host 可以创建多个 Cluster，拥有的 Cluster 对象即为纳管的集群 Task、Pipeline 对象会自动同步到集群下的全部 Cluster 集群中，无需人工触发。 当下发一个流水线任务时，需要创建一个 PipelineRun 对象。PipelineRun 是可以跨集群的，而 TaskRun 不行。 Controller 会根据 PipelineRun 中设置的 cluster 字段，将 PipelineRun 分发到指定的集群中，由集群内的 Controller 执行具体的任务，再将 PipelineRun 的状态更新到主集群内的 PipelineRun 对象中。 事件驱动 建议在每个集群中安装一个 Nats 组件，通过边缘集群的模式，可以将全部的事件汇总到一个集群，或者若干个网络分区的集群。 在事件中，主要定义了以下 Topic: 探活类，每个主机、集群会有定时检测，能够看到探活的事件 执行任务类，执行 TaskRun、PipelineRun 任务的事件 巡检类，TaskRun 执行定时任务巡检任务时，会推送相关的检测事件 Webhook类，用户自定义的一些运维事件，告警、通知等 "},"opscli.html":{"url":"opscli.html","title":"Opscli","keywords":"","body":"opscli 功能简介 批量远程执行命令 批量分发文件 创建 Ops Controller CRD 资源 主要分为三类 CRD 资源: Host, Cluster, Task 支持的操作系统 Linux macOS "},"opscli-install.html":{"url":"opscli-install.html","title":"Install","keywords":"","body":"opscli 安装 安装 单机安装 国内使用: PROXY=https://ghfast.top/ curl -sfL $PROXY/https://raw.githubusercontent.com/shaowenchen/ops/main/getcli.sh | VERSION=latest PROXY=$PROXY sh - 国外使用: curl -sfL https://raw.githubusercontent.com/shaowenchen/ops/main/getcli.sh | VERSION=latest sh - 批量安装 将需要安装的全部主机 ip 都写入到 hosts.txt 文件中，然后使用 opscli shell 命令批量安装，凭证默认为当前用户的 ~/.ssh/id_rsa。 国内使用: /usr/local/bin/opscli shell --content \"curl -sfL https://ghproxy.chenshaowen.com/https://raw.githubusercontent.com/shaowenchen/ops/main/getcli.sh | VERSION=latest sh -\" -i hosts.txt 国外使用: /usr/local/bin/opscli shell --content \"curl -sfL https://raw.githubusercontent.com/shaowenchen/ops/main/getcli.sh | VERSION=latest sh -\" -i hosts.txt 版本升级 单机 sudo /usr/local/bin/opscli upgrade 批量 /usr/local/bin/opscli shell --content \"sudo /usr/local/bin/opscli upgrade\" -i hosts.txt 自动补全 bash echo 'source >~/.bashrc zsh echo 'source >~/.zshrc 更多 /usr/local/bin/opscli --help "},"opscli-shell.html":{"url":"opscli-shell.html","title":"Shell","keywords":"","body":"opscli shell command 指定操作目标清单 指定主机 -i 1.1.1.1 通过 --username 指定用户名，--password 指定密码。 批量主机 通过文件指定: -i hosts.txt cat hosts.txt 1.1.1.1 2.2.2.2 opscli 会从每行中正则匹配 ip 地址，作为目标地址。 通过逗号分割指定: -i 1.1.1.1,2.2.2.2 集群全部节点 -i ~/.kube/config --nodename all -i 默认值为 ~/.kube/config。 集群指定节点 -i ~/.kube/config --nodename node1 node1 为节点名称。 查看集群镜像 单机 /usr/local/bin/opscli task -f ~/.ops/tasks/list-podimage.yaml --namespace all 集群批量操作 全部节点 opscli shell --content \"uname -a\" --nodename all 指定节点 opscli shell --content \"uname -a\" --nodename node1 指定 kubeconfig 默认 kubeconfig 为 ~/.kube/config，可以通过 -i 参数指定。 opscli shell -i ~/Documents/opscli/prod --content \"uname -a\" --nodename node1 "},"opscli-task.html":{"url":"opscli-task.html","title":"Task","keywords":"","body":"opscli task command -i 指定操作目标清单 指定主机 -i 1.1.1.1 通过 --username 指定用户名，--password 指定密码。 批量主机 -i hosts.txt cat hosts.txt 1.1.1.1 2.2.2.2 opscli 会从每行中正则匹配 ip 地址，作为目标地址。 集群全部节点 -i ~/.kube/config --nodename all -i 默认值为 ~/.kube/config。 集群指定节点 -i ~/.kube/config --nodename node1 node1 为节点名称。 更新 /etc/hosts 主机 远程到主机 1.1.1.1 ，更新 /etc/hosts 文件。 /usr/local/bin/opscli task -f ~/.ops/tasks/set-hosts.yaml --ip 1.2.3.4 --domain test.com --i 1.1.1.1 --port 2222 --username root 如果需要清理加上 --clear 参数即可。 集群全部节点 /usr/local/bin/opscli task -f ~/.ops/tasks/set-hosts.yaml --ip 1.2.3.4 --domain test.com --i ~/.kube/config --nodename all 集群指定节点 /usr/local/bin/opscli task -f ~/.ops/tasks/set-hosts.yaml --ip 1.2.3.4 --domain test.com --i ~/.kube/config --nodename node1 应用安装 安装 Istio /usr/local/bin/opscli task -f ~/.ops/tasks/app-istio.yaml --version 1.13.7 --kubeconfig /etc/kubernetes/admin.conf --version 默认值为 1.13.7，--kubeconfig 默认值为 /etc/kubernetes/admin.conf。 卸载 Istio /usr/local/bin/opscli task -f ~/.ops/tasks/app-istio.yaml --version 1.13.7 --kubeconfig /etc/kubernetes/admin.conf --action delete 上传文件 上传到 Server /usr/local/bin/opscli task -f tasks/file-upload.yaml --api https://gh-uploadapi.chenshaowen.com/api/v1/files --localfile dockerfile > Run Task ops-system/file-upload on 127.0.0.1 (1/1) upload file Please use the following command to download the file: opscli file --api https://gh-uploadapi.chenshaowen.com/api/v1/files --aeskey a9f891afe71fda777b05a7063068360a914e83848d7da46d7513aee86c053f6c --direction download --remotefile https://gh-uploadapi.chenshaowen.com/uploadbases/cdn0/raw/1721615659-dockerfile.aes 上传到 S3 /usr/local/bin/opscli task -f tasks/file-upload.yaml --ak xxx --sk xxx --region beijing --endpoint ks3-cn-beijing.ksyun.com --bucket xxx --localfile dockerfile --remotefile s3://dockerfile 下载文件 从 Server 下载 /usr/local/bin/opscli task -f task -f tasks/file-download.yaml --api https://gh-uploadapi.chenshaowen.com/api/v1/files --aeskey a9f891afe71fda777b05a7063068360a914e83848d7da46d7513aee86c053f6c --remotefile https://gh-uploadapi.chenshaowen.com/uploadbases/cdn0/raw/1721615659-dockerfile.aes --localfile dockerfile1 > Run Task ops-system/file-download on 127.0.0.1 (1/1) download file success download https://gh-uploadapi.chenshaowen.com/uploadbases/cdn0/raw/1721615659-dockerfile.aes to dockerfile1 从 S3 下载 /usr/local/bin/opscli task -f tasks/file-download.yaml --ak xxx --sk xxx --region beijing --endpoint ks3-cn-beijing.ksyun.com --bucket xxx --localfile dockerfile2 --remotefile s3://dockerfile > Run Task ops-system/file-download on 127.0.0.1 (1/1) download file success download s3 dockerfile to dockerfile2 "},"opscli-file.html":{"url":"opscli-file.html","title":"File","keywords":"","body":"opscli file command 主机 - 本地与对象存储互传文件 设置 AK\\SK export ak= export sk= 上传本地文件 ./tmp.log 到对象存储 s3://logs/tmp.log /usr/local/bin/opscli file --direction upload --localfile ./tmp.log --remotefile s3://logs/tmp.log --bucket obs-test --bucket 为 S3 bucket 名称，--region 为 S3 bucket 所在区域，--endpoint 为 S3 bucket 的 endpoint，--direction 为上传方向，--localfile 为本地文件，--remotefile 为远程文件。 下载 S3 s3://logs/tmp.log 到本地文件 ./tmp1.log /usr/local/bin/opscli file --direction download --localfile ./tmp1.log --remotefile s3://logs/tmp.log --bucket obs-test 清理 AK\\SK unset ak unset sk 主机 - 本地与 API Server 互传文件 提供本地加解密，与服务器端进行文件传输 上传 /usr/local/bin/opscli file --direction upload --api https://gh-uploadapi.chenshaowen.com/api/v1/files --localfile ./tmp.log Please use the following command to download the file: opscli file --api https://gh-uploadapi.chenshaowen.com/api/v1/files --direction download --remotefile https://download_url_link.com.aes 这里的 api 提供上传服务，aeskey 为空字符串时自动生成一个随机秘钥，如果不设置 aeskey 默认为 unset 将不会进行文件加密。 下载 /usr/local/bin/opscli file --api https://gh-uploadapi.chenshaowen.com/api/v1/files --aeskey xxx --direction download --remotefile https://download_url_link.com.aes 集群 - 本地与 API Server 互传文件 上传 /usr/local/bin/opscli file -i ~/.kube/config --nodename node1 --direction upload --api https://gh-uploadapi.chenshaowen.com/api/v1/files --aeskey \"\" --localfile /root/tmp.log --runtimeimage shaowenchen/ops-cli 下载 /usr/local/bin/opscli file -i ~/.kube/config --nodename xxx --direction download --api https://gh-uploadapi.chenshaowen.com/api/v1/files --aeskey xxx --localfile /root/tmp1.log --remotefile https://gh-uploadapi.chenshaowen.com/uploadbases/cdn0/raw/1721621949-tmp.log.aes --runtimeimage shaowenchen/ops-cli 集群 - 本地与对象存储互传文件 上传 /usr/local/bin/opscli file -i ~/.kube/config --nodename xxx --direction upload --ak xxx --sk xxx --region beijing --endpoint ks3-cn-beijing.ksyun.com --bucket multimodal --localfile /root/tmp.log --remotefile s3://logs/tmp.log --runtimeimage shaowenchen/ops-cli 下载 /usr/local/bin/opscli file -i ~/.kube/config --nodename xxx --direction download --ak xxx --sk xxx --region beijing --endpoint ks3-cn-beijing.ksyun.com --bucket multimodal --localfile /root/tmp2.log --remotefile s3://logs/tmp.log --runtimeimage shaowenchen/ops-cli 集群 - 镜像文件拷贝到本地 /usr/local/bin/opscli file -i ~/.kube/config --nodename xxx --direction download --localfile /root/opscli-copy --remotefile shaowenchen/ops-cli:latest:///usr/local/bin/opscli "},"opscli-case.html":{"url":"opscli-case.html","title":"Case","keywords":"","body":"opscli 使用案例 在 kubectl pod 中测试指定节点的磁盘 IO 性能 安装 opscli for alpine sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories apk add curl curl -sfL https://ghproxy.chenshaowen.com/https://raw.githubusercontent.com/shaowenchen/ops/main/getcli.sh |VERSION=latest sh - 在节点安装 fio opscli shell --content \"apt-get install fio -y\" --nodename node1 在节点上测试磁盘 IO 性能 opscli task -f ~/.ops/tasks/get-diskio-byfio.yaml --size 1g --filename=/tmp/testfile --nodename node1 其中 size 为测试文件大小，filename 为测试文件路径，nodename 为测试节点名称。 (1/8) Rand_Read_Testing read: IOPS=105k, BW=410MiB/s (430MB/s)(1024MiB/2498msec) -> 4k 随机读 410 MiB/s (2/8) Rand_Write_Testing write: IOPS=55.9k, BW=218MiB/s (229MB/s)(1024MiB/4688msec) -> 4k 随机写 218 MiB/s (3/8) Sequ_Read_Testing read: IOPS=51.8k, BW=6481MiB/s (6796MB/s)(1024MiB/158msec) -> 128k 顺序读 6481 MiB/s (4/8) Sequ_Write_Testing write: IOPS=30.7k, BW=3835MiB/s (4022MB/s)(1024MiB/267msec) -> 128k 顺序写 3835 MiB/s (5/8) Rand_Read_IOPS_Testing read: IOPS=80.4k, BW=314MiB/s (329MB/s)(1024MiB/3261msec) -> 4k 下读 IOPS 为 80.4k (6/8) Rand_Write_IOPS_Testing write: IOPS=83.4k, BW=326MiB/s (342MB/s)(1024MiB/3143msec) -> 4k 下写 IOPS 为 83.4k (7/8) Rand_Read_Latency_Testing lat (usec): min=34, max=457722, avg=57.78, stdev=1630.32 -> 4k 读延时为 57.78 us (8/8) Rand_Write_Latency_Testing lat (usec): min=35, max=664838, avg=385.12, stdev=5335.64 -> 4k 写延时为 385.12 us 给集群 GPU 主机配置巡检 在全部 master 节点上安装 Opscli opscli task -f ~/.ops/tasks/install-opscli.yaml -i master-ips.txt 在能 ssh 全部节点的机器上，创建访问主机的 ssh 密钥 kubectl -n ops-system create secret generic host-secret --from-file=privatekey=/root/.ssh/id_rsa 添加全部 task 模板 kubectl apply -f ~/.ops/tasks/ 自动发现主机 kubectl apply -f - 自动打上标签 kubectl apply -f - GPU 掉卡巡检 kubectl apply -f - GPU ECC 巡检 kubectl apply -f - GPU Fabric 巡检 kubectl apply -f - GPU Zombie 巡检 kubectl apply -f - 定时清理磁盘 kubectl apply -f - "},"opsserver.html":{"url":"opsserver.html","title":"Opsserver","keywords":"","body":"ops-server 功能简介 ops-server 是一个 HTTP 服务，提供了一些 RESTful API，用于对外提供 API 服务。 这样的用途包括： 通过 HTTP API 来批量远程执行命令 通过 HTTP API 来批量分发文件 通过 HTTP API 来创建 Ops Controller CRD 资源 关于权限 默认密码是 ops 可以通过给 Server 服务设置环境变量 SERVER_TOKEN 自定义密码。 对象管理 任务执行 "},"opscontroller.html":{"url":"opscontroller.html","title":"Opscontroller","keywords":"","body":"Ops-controller-manager 功能简介 ops-controller-manager 是一个 Kubernetes Operator。它提供了三种对象：Host, Cluster, Task。 Host Host 对象用于描述一个主机，比如主机名，IP 地址，SSH 用户名，SSH 密码，SSH 私钥等。 Cluster Cluster 对象用于描述一个集群，比如集群名，集群的主机数量、Pod 数量、负载、CPU、内存等。 Task Task 对象用于描述一个任务，比如一次性任务、周期任务。 安装 安装 Helm curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash 添加 Helm 仓库 helm repo add ops https://www.chenshaowen.com/ops/charts helm repo update 安装 ops-controller-manager helm install myops ops/ops --version 2.0.0 --namespace ops-system --create-namespace 查看安装结果 kubectl get pods -n ops-system 卸载 helm -n ops-system uninstall myops 需要注意的是 ops-controller-manager 默认只会处理 ops-system 命名空间下的 CRD 资源。 如果需要变更，可以修改 Env 中 ACTIVE_NAMESPACE 的值，指定某一个命令空间，如果为空，则表示处理所有命名空间。 "},"opscontroller-host.html":{"url":"opscontroller-host.html","title":"Host","keywords":"","body":"Ops-controller-manager host 对象 直接使用 create 子命令创建 /usr/local/bin/opscli create host --name dev1 -i 1.1.1.1 --port 2222 --username root --password xxx --namespace ops-system 使用 yaml 文件创建 apiVersion: crd.chenshaowen.com/v1 kind: Host metadata: name: dev1 namespace: ops-system spec: address: 1.1.1.1 port: 2222 privatekey: base64 encoded private key username: root privatekeypath: ~/.ssh/id_rsa timeoutseconds: 10 查看对象 kubectl get hosts dev1 -n ops-system NAME HOSTNAME ADDRESS DISTRIBUTION ARCH CPU MEM DISK HEARTTIME HEARTSTATUS dev1 node1 1.1.1.1 centos x86_64 4 7.8G 52G 54s successed "},"opscontroller-cluster.html":{"url":"opscontroller-cluster.html","title":"Cluster","keywords":"","body":"Ops-controller-manager cluster 对象 直接使用 create 子命令创建 /usr/local/bin/opscli create cluster -i ~/.kube/config --name dev1 --namespace ops-system 使用 yaml 文件创建 apiVersion: crd.chenshaowen.com/v1 kind: Cluster metadata: name: dev1 namespace: ops-system spec: config: base64 encoded kubeadm config server: https://1.1.1.1:6443 查看对象 kubectl get cluster dev1 -n ops-system NAME SERVER VERSION NODE RUNNING TOTALPOD CERTDAYS STATUS dev1 https://1.1.1.1:6443 v1.21.0 1 15 16 114 successed "},"opscontroller-task.html":{"url":"opscontroller-task.html","title":"Task","keywords":"","body":"Ops-controller-manager task 对象 直接使用 create 子命令创建 /usr/local/bin/opscli create task --name t1 --typeref host --nameref dev1 --filepath ./task/get-osstaus.yaml 通过 --typeref host --nameref dev1 指定任务执行的主机。 使用 yaml 文件创建 如果不指定 typeref ，那么任务将在 ops-controller-manager pod 中执行。 下面是一个定时任务，每分钟检查一次 http 状态码，如果不是 200，那么发送通知。 apiVersion: crd.chenshaowen.com/v1 kind: Task metadata: name: alert-http-status-dockermirror namespace: ops-system spec: desc: alert crontab: \"*/1 * * * *\" variables: url: default: http://1.1.1.1:5000/ expect: default: \"200\" message: default: ${url} http status is not ${expect} steps: - name: get status content: curl -I -m 10 -o /dev/null -s -w %{http_code} ${url} - name: notifaction when: ${result} != ${expect} content: | curl -X POST 'https://365.kdocs.cn/woa/api/v1/webhook/send?key=xxx' -H 'content-type: application/json' -d '{ \"msgtype\": \"text\", \"text\": { \"content\": \"${message}\" } }' 查看对象 kubectl get task t1 -n ops-system kubectl get task -n ops-system NAME CRONTAB TYPEREF NAMEREF NODENAME ALL STARTTIME RUNSTATUS alert-http-status-dockermirror */1 * * * * "},"nats.html":{"url":"nats.html","title":"Nats","keywords":"","body":"Nats 用途 Ops 通过 Nats 组件，导出相关的事件，主要有两类: CRD 的状态，包括主机、集群的状态，TaskRun、PipelineRun 的状态 alert 定时巡检上报的状态信息 下面提供 Nats 组件的安装与配置。这里采用的是，一个主集群，若干边缘集群的方式，边缘集群会将事件转发到主集群，在主集群统一进行处理。 添加 Helm Repo 添加仓库 helm repo add nats https://nats-io.github.io/k8s/helm/charts/ helm repo update 查看可配置的字段 helm show values nats/nats 部署主集群 设置 Nats 的基本信息 export adminpassword=mypassword export apppassword=mypassword 生成 nats-values.yaml cat nats-values.yaml config: jetstream: enabled: true fileStore: enabled: false dir: /data memoryStore: enabled: true maxSize: 1Gi pvc: enabled: false storageClassName: my-sc cluster: enabled: true leafnodes: enabled: true merge: accounts: SYS: users: - user: admin password: ${adminpassword} APP: users: - user: app password: ${apppassword} jetstream: true system_account: SYS container: image: repository: nats tag: 2.10.20-alpine natsBox: container: image: repository: nats-box tag: 0.14.5 reloader: enabled: true image: repository: natsio/nats-server-config-reloader tag: 0.15.1 EOF 数据被持久化到内存中，如果需要存储到磁盘，需要设置 fileStore。 安装 nats helm -n ops-system install nats nats/nats --version 1.2.4 -f nats-values.yaml helm -n ops-system uninstall nats 暴露 Nats 服务端口 kubectl patch svc nats -p '{\"spec\":{\"type\":\"NodePort\",\"ports\":[{\"port\":4222,\"nodePort\":32223,\"targetPort\":\"nats\"},{\"port\":7422,\"nodePort\":32222,\"targetPort\":\"leafnodes\"}]}}' -n ops-system 查看负载 kubectl -n ops-system get pod,svc | grep nats pod/nats-0 2/2 Running 0 15h pod/nats-1 2/2 Running 0 15h pod/nats-2 2/2 Running 0 15h pod/nats-box-6bb86df889-xcr6x 1/1 Running 0 15h service/nats NodePort 10.100.109.24 4222:32223/TCP,7422:32222/TCP 15h service/nats-headless ClusterIP None 4222/TCP,7422/TCP,6222/TCP,8222/TCP 15h 部署边缘节点 添加仓库 helm repo add nats https://nats-io.github.io/k8s/helm/charts/ helm repo update 设置主集群的 nats 信息 export natsendpoint=x.x.x.x:32222 设置 nats 的 server_name export natsservername=need-to-be-unique 生成 nats-values.yaml 需要注意的是，不同集群的 server_name 不能相同，否则会有重复连接的问题。 cat nats-values.yaml config: leafnodes: enabled: true merge: remotes: - urls: - nats://admin:${adminpassword}@${natsendpoint} account: SYS - urls: - nats://app:${apppassword}@${natsendpoint} account: APP merge: server_name: ${natsservername} accounts: SYS: users: - user: admin password: ${adminpassword} APP: users: - user: app password: ${apppassword} jetstream: true system_account: SYS container: image: repository: nats tag: 2.10.20-alpine natsBox: container: image: repository: natsio/nats-box tag: 0.14.5 reloader: enabled: true image: repository: natsio/nats-server-config-reloader tag: 0.15.1 EOF 安装 nats helm install nats nats/nats --version 1.2.4 -f nats-values.yaml -n ops-system Nats 常用命令 测试 Nats kubectl -n ops-system exec -it deployment/nats-box -- sh 订阅消息 nats --user=app --password=${apppassword} sub \"ops.>\" 发布消息 nats --user=app --password=${apppassword} pub ops.test \"mymessage mycontent\" 创建 stream 持久化消息 nats --user=app --password=${apppassword} stream add ops --subjects \"ops.>\" --ack --max-msgs=-1 --max-bytes=-1 --max-age=168h --storage file --retention limits --max-msg-size=-1 --discard=old --replicas 1 --dupe-window=2m 生产环境中，推荐使用 file 存储，并且 replica 设置为 3。 查看 stream 事件 nats --user=app --password=${apppassword} stream view ops 查看 stream 配置 nats --user=app --password=${apppassword} stream info ops 查看集群信息 nats --user=admin --password=${adminpassword} server report jetstream 这里可以看到，主集群的信息，边缘集群的信息，以及连接的信息。 查看 stream 的 subjects nats --user=app --password=${apppassword} stream subjects ops 压力测试 nats --user=app --password=${apppassword} bench benchsubject --pub 1 --sub 10 参考 https://docs.nats.io/running-a-nats-service/configuration#jetstream https://docs.nats.io/running-a-nats-service/configuration/leafnodes/leafnode_conf https://docs.nats.io/running-a-nats-service/configuration/gateways/gateway#gateway-configuration-block "}}